{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1bfa20-f9cb-41ab-8b6f-d9066cdffc83",
   "metadata": {},
   "source": [
    "# Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf13978-138f-4e0d-9774-11cd51809a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit, prange\n",
    "import matplotlib as mpl\n",
    "import concurrent.futures\n",
    "from numba.typed import List\n",
    "from numba.np import random as nbrandom\n",
    "from itertools import accumulate\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c18376-0788-446c-bcc0-c76d9dd64919",
   "metadata": {},
   "source": [
    "## 2.1 Diffusion Limited Aggregation (**DLA**)\n",
    "\n",
    "The diffusion-limited aggregation (**DLA**) is a growth model based on diffusing particles.  The growth is started with a single seed (just a small square object in a single lattice point, at the bottom of the computational domain).  As described in detail in the lecture notes, **DLA** can be modeled by solving the time-independent diffusion equation (i.e. the Laplace equation), locating growth candidates around the cluster, and assigning a growth probability \\( $p_g$ \\) for each growth candidate, as a function of the concentration of diffusing nutrients at that growth location.  Next, a single growth candidate is added to the cluster with probability \\( $p_g$ \\).  After this growth step, the diffusion equation is again solved, and the process is iterated for a large number of growth steps.  You currently have almost all the tools available for a simulation of the **DLA** growth model.  Let us take a closer look at the growth model itself, allowing you to insert this into your programs.  A growth candidate is basically a lattice site that is not part of the object, but whose north, east, south, or west neighbor is part of the object. the object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39725cb-cdb8-4793-b913-e635f2695fe0",
   "metadata": {},
   "source": [
    "The probability for growth at each of the growth candidates is calculated by\n",
    "\n",
    "$$\n",
    "p_g(i,j) = \\frac{c_{i,j}^\\eta}{\\sum_{\\mathrm{growth\\ candidates}} c_{i,j}^\\eta}\n",
    "$$\n",
    "\n",
    "The parameter $\\eta$ determines the shape of the object. For $\\eta$ = 1 we get the normal DLA cluster. For $\\eta$ < 1 the object becomes more compact (with $\\eta$ = 0 resulting in the Eden cluster), and for $\\eta$ > 1 the cluster becomes more open (and finally resembles say a lightning flash).\n",
    "\n",
    "Modelling the growth is now a simple procedure.  A set is created of all growth candidates with their associated weights, and a single candidate is chosen. Hint: use `numpy.choice` with the $p$ parameter for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf19871-7401-4db3-8eb9-9be964b0634a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af02881-25aa-4806-9eaa-26776c870e2e",
   "metadata": {},
   "source": [
    "### **A**. (4 points)\n",
    "Implement the growth model, paying special attention to the calcu\u0002lation of the growth probabilities. Run a number of growth simulations. Try to do this for a domain of size 100 × 100 and investigate the influence of the $\\eta$ parameter. Can you still optimise by setting your $\\omega$ parameter in the SOR iteration to a specific value?\n",
    "\n",
    "Hint: the SOR iteration is run over and over again on a slowly growing object. As\n",
    "the growth step is constructed in such a way that on average only one lattice site\n",
    "is grown to the object, the concentration fields will hardly change. Therefore, it is\n",
    "advantageous to start a new SOR iteration with the solution of the previous growth\n",
    "step. Also, you can start the simulation with the analytical result for the empty\n",
    "system, the linear concentration gradient of this equation\n",
    "\n",
    "$$\n",
    "\\lim\\limits_{t \\to \\infty} c(y,t) = y.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233b690-be31-44b4-af31-5f22a84cbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the concentration field and DLA seed at the bottom center\n",
    "def initialize_domain(N: int) -> tuple:\n",
    "    c = np.zeros((N, N))\n",
    "    c[:, -1] = 1  # Right boundary condition (ensuring diffusion)\n",
    "    objects = np.zeros_like(c, dtype=bool)\n",
    "    objects[N//2, 1] = True  # Seed at the bottom center\n",
    "    return c, objects\n",
    "\n",
    "# Solve the Laplace equation using the Successive Over-Relaxation (SOR) method\n",
    "@njit\n",
    "def SOR(c: np.ndarray, objects: np.ndarray, omega: float, tolerance: float, max_iter: int) -> int:\n",
    "    N = c.shape[0]\n",
    "    for iter in range(max_iter):\n",
    "        # Boundary conditions\n",
    "        # SOR boundary conditions\n",
    "        c[:, -1] = 1.  # Right boundary = 1\n",
    "        c[:, 0] = 0.   # Left boundary = 0\n",
    "        c[0, :] = c[1, :]  # Top boundary = second row\n",
    "        c[-1, :] = c[-2, :]  # Bottom boundary = second last row\n",
    "        \n",
    "        delta = 0.\n",
    "        for i in range(1, N-1):\n",
    "            for j in range(1, N-1):\n",
    "                if objects[i, j]:\n",
    "                    continue\n",
    "                old_c = c[i, j]\n",
    "                # Over-relaxation update\n",
    "                c[i, j] = max(omega * 0.25 * (c[i-1, j] + c[i+1, j] + c[i, j-1] + c[i, j+1]) + (1 - omega) * c[i, j], 0)\n",
    "                delta = max(delta, abs(c[i, j] - old_c))\n",
    "\n",
    "        if delta <= tolerance:\n",
    "            break\n",
    "    return iter  # Return the number of iterations\n",
    "\n",
    "def choose_site(c: np.ndarray, objects: np.ndarray, eta: float) -> tuple:\n",
    "    # Identify potential growth sites by checking neighboring occupied sites\n",
    "    left = np.roll(objects, -1, axis=0)\n",
    "    left[-1, :] = False  # Prevent wrapping around bottom boundary\n",
    "    right = np.roll(objects, 1, axis=0)\n",
    "    right[0, :] = False  # Prevent wrapping around top boundary\n",
    "    up = np.roll(objects, 1, axis=1)\n",
    "    up[:, 0] = False  # Prevent wrapping around left boundary\n",
    "    down = np.roll(objects, -1, axis=1)\n",
    "    down[:, -1] = False  # Prevent wrapping around right boundary\n",
    "\n",
    "    temp = np.logical_or(left, right)\n",
    "    temp = np.logical_or(temp, up)\n",
    "    temp = np.logical_or(temp, down)\n",
    "    growth_candidates = np.logical_and(temp, ~objects)  # Sites adjacent to existing objects\n",
    "\n",
    "    # Get all potential growth sites\n",
    "    row, col = np.where(growth_candidates)\n",
    "\n",
    "    # Ensure numerical stability by preventing division by zero\n",
    "    c_values = c[row, col]\n",
    "    c_values[c_values <= 1e-6] = 1e-6  # Replace extremely small values with a minimum threshold\n",
    "\n",
    "    sum_c = np.sum(c_values**eta)\n",
    "    if sum_c == 0 or np.isnan(sum_c):\n",
    "        return None, None\n",
    "\n",
    "    # Compute probability of selecting each site\n",
    "    pg = c_values**eta / sum_c  \n",
    "\n",
    "    # Choose a growth site based on the computed probability\n",
    "    growth_site_idx = np.random.choice(len(row), size=1, p=pg)\n",
    "\n",
    "    return row[growth_site_idx][0], col[growth_site_idx][0]\n",
    "\n",
    "# Simulates the DLA growth process\n",
    "def DLA_growth(c: np.ndarray, objects: np.ndarray, eta: float, DLA_iter: int, \n",
    "               omega: float=1.7, tolerance: float=1e-4, max_iter: int=10000) -> list:\n",
    "    iters = []\n",
    "    for i in range(DLA_iter):\n",
    "        sor_iter = SOR(c, objects, omega, tolerance, max_iter)\n",
    "        iters.append(sor_iter)\n",
    "\n",
    "        if sor_iter == max_iter:\n",
    "            print(f'Warning: SOR did not converge in {max_iter} iterations')\n",
    "\n",
    "        x, y = choose_site(c, objects, eta)\n",
    "        if x is None:\n",
    "            break\n",
    "\n",
    "        objects[x, y] = True\n",
    "        c[x, y] = 0.\n",
    "\n",
    "    return iters\n",
    "\n",
    "def plot_all_objects(N: int, eta_values: list, DLA_iter: int, omega: float=1.7):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 16))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, eta in enumerate(eta_values):\n",
    "        c, objects = initialize_domain(N)\n",
    "        DLA_growth(c, objects, eta, DLA_iter, omega)\n",
    "        \n",
    "        cmap = plt.cm.viridis\n",
    "        cmap.set_under('black')\n",
    "        \n",
    "        img = axes[i].imshow(c.T, origin='lower', cmap=cmap, vmin=1e-4)\n",
    "        axes[i].set_title(fr'400 steps and $\\eta = {eta}$')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.1)\n",
    "    fig.colorbar(img, ax=axes, location=\"right\", shrink=0.3)\n",
    "    plt.savefig('figures/A_eta.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d198329-33a0-4f26-a730-12a52bca3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "if __name__ == \"__main__\":\n",
    "    N = 100\n",
    "    DLA_iter = 400\n",
    "    eta_values = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "    plot_all_objects(N, eta_values, DLA_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435e1e4-2fe7-4a17-9914-5ddd6138382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "omega_values = np.arange(1.5, 1.95, 0.1)  # ω from 1.5 to 1.95 with step 0.1\n",
    "eta_values = [0.0, 0.5, 1.0, 1.5, 2.0]  # Different η values\n",
    "iterations_dict = {eta: [] for eta in eta_values}\n",
    "optimal_omega_dict = {}\n",
    "\n",
    "# Run SOR with different ω and η values\n",
    "for eta in eta_values:\n",
    "    min_iterations = float(\"inf\")\n",
    "    best_omega = None\n",
    "    for omega in omega_values:\n",
    "        c, objects = initialize_domain(N)\n",
    "        iterations = DLA_growth(c, objects, eta, DLA_iter, omega)\n",
    "        # Compute total iterations instead of average\n",
    "        total_iterations = sum(iterations)\n",
    "        iterations_dict[eta].append(total_iterations)\n",
    "        \n",
    "        if total_iterations < min_iterations:\n",
    "            min_iterations = total_iterations\n",
    "            best_omega = omega\n",
    "    \n",
    "    optimal_omega_dict[eta] = best_omega\n",
    "\n",
    "# Store results for different η values\n",
    "plt.figure(figsize=(6, 5))\n",
    "for eta in eta_values:\n",
    "    plt.plot(omega_values, iterations_dict[eta], marker='o', linestyle='-', label=f\"$\\\\eta$ = {eta}\")\n",
    "\n",
    "plt.xlabel(r'$\\omega$')\n",
    "plt.ylabel('SOR Iterations')\n",
    "plt.title(r'SOR Iteration Count vs. Relaxation Factor for Different $\\eta$ values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/A_omega.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Print optimal omega for each eta\n",
    "for eta, best_omega in optimal_omega_dict.items():\n",
    "    print(f\"Optimal ω for η = {eta}: {best_omega}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e4f31-1ece-4bef-928d-f0e2436c970a",
   "metadata": {},
   "source": [
    "### **Optional**: (1 point) \n",
    "Think of a way to reduce the time required to solve the diffusion equation. Compare your results for the 100 × 100 grid in question A and try larger grid sizes. Some suggestions: parallelize one of the iteration schemes in the previous exercise set, and possibly use a GPU to do the calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3bb65-8788-4978-b00a-cc6993feeec0",
   "metadata": {},
   "source": [
    "## **Be careful when run this cell, once you run it, the parallelization will lead MUCH MUCH slower execution to other cells!!! Use 'restart kernel' to avoid this issue.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785a8cf-5cc5-48c6-9cfd-3e0611a6e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimized parallel SOR method\n",
    "@njit(parallel=True)\n",
    "def SOR_parallel(c: np.ndarray, objects: np.ndarray, omega: float, tolerance: float, max_iter: int) -> int:\n",
    "    N = c.shape[0]\n",
    "    for iter in range(max_iter):\n",
    "        c[:, -1] = 1.\n",
    "        c[:, 0] = 0.\n",
    "        c[0, :] = c[1, :]\n",
    "        c[-1, :] = c[-2, :]\n",
    "\n",
    "        delta = 0.\n",
    "        for i in prange(1, N-1):  # Parallel loop\n",
    "            for j in range(1, N-1):\n",
    "                if objects[i, j]:\n",
    "                    continue\n",
    "                old_c = c[i, j]\n",
    "                c[i, j] = max(omega * 0.25 * (c[i-1, j] + c[i+1, j] + c[i, j-1] + c[i, j+1]) + (1 - omega) * c[i, j], 0)\n",
    "                delta = max(delta, abs(c[i, j] - old_c))\n",
    "\n",
    "        if delta <= tolerance:\n",
    "            break\n",
    "    return iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e307b-2730-4f03-bd07-634c44499c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare execution time for sequential vs parallel SOR --- Simulation\n",
    "N_values = [100, 500, 1000]  # Run for different grid sizes\n",
    "omega = 1.7  # Relaxation factor\n",
    "tolerance = 1e-4\n",
    "max_iter = 10000\n",
    "\n",
    "results = {}\n",
    "for N in N_values:\n",
    "    # Initialize the grid\n",
    "    c_seq, objects_seq = np.zeros((N, N)), np.zeros((N, N), dtype=bool)\n",
    "    c_par, objects_par = np.copy(c_seq), np.copy(objects_seq)\n",
    "\n",
    "    # Measure time for original sequential SOR\n",
    "    start_time = time.time()\n",
    "    SOR(c_seq, objects_seq, omega, tolerance, max_iter)\n",
    "    sequential_time = time.time() - start_time\n",
    "\n",
    "    # Measure time for parallel SOR\n",
    "    start_time = time.time()\n",
    "    SOR_parallel(c_par, objects_par, omega, tolerance, max_iter)\n",
    "    parallel_time = time.time() - start_time\n",
    "\n",
    "    results[N] = (sequential_time, parallel_time)\n",
    "\n",
    "    # Print the time comparison for different grid size N\n",
    "    print(f\"N = {N}\")\n",
    "    print(f\"Sequential SOR Time: {sequential_time:.4f} seconds\")\n",
    "    print(f\"Parallel SOR Time: {parallel_time:.4f} seconds\")\n",
    "    print(f\"Speedup Factor: {sequential_time / parallel_time:.2f}x\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134e716-5397-4666-a880-7278eb6b8daf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc48507-4804-4b4b-95a5-374ce5c6a9ab",
   "metadata": {},
   "source": [
    "## 2.2 Monte Carlo simulation of DLA\n",
    "\n",
    "DLA can also be simulated by releasing random walkers on a grid, and letting them\n",
    "walk until they hit the cluster. When they hit, the walkers are stopped and become\n",
    "part of the cluster.\n",
    "One random walker at a time is released in the system. It moves in steps, which\n",
    "are randomly chosen to be one lattice point up, down, left, or right. If the walker\n",
    "reaches a cell neighboring the cluster, the walker is stopped there, so that the cell\n",
    "with the walker becomes part of the cluster.\n",
    "To simulate with the same boundary conditions as above, start the walkers on a\n",
    "randomly chosen point on the top boundary. If a walker walks out of the system\n",
    "on the top or bottom boundary it is removed and a new one created instead. If it\n",
    "walks across the left or right boundary, it should enter the system from the other\n",
    "side, as periodic boundary conditions were assumed in the horizontal direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79d5cf-6aca-4f3e-8a7d-f99aaf089f58",
   "metadata": {},
   "source": [
    "### **B**. (2 points) \n",
    "Implement the Monte Carlo version of DLA. Compare the resulting \n",
    "cluster to those obtained with the diffusion equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a778713-e568-4093-99f1-fc03a1e19f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_grid(size):\n",
    "    grid = np.zeros((size, size), dtype=int)\n",
    "    grid[size // 2, 0] = 1  # initial atom in the middle of the bottom row\n",
    "    return grid\n",
    "\n",
    "def move_walker(x, y, size):\n",
    "    direction = random.choice([(0, 1), (0, -1), (1, 0), (-1, 0)])  # 只允许上下左右移动\n",
    "    x_new, y_new = x + direction[0], y + direction[1]\n",
    "    # wrap around at the edges\n",
    "    x_new = x_new % size\n",
    "    return x_new, y_new\n",
    "\n",
    "def is_adjacent(x, y, grid, size):\n",
    "    return ((x > 0 and grid[x - 1, y] == 1) or\n",
    "            (x < size - 1 and grid[x + 1, y] == 1) or\n",
    "            (y > 0 and grid[x, y - 1] == 1) or\n",
    "            (y < size - 1 and grid[x, y + 1] == 1))\n",
    "\n",
    "def simulate_dla(size=100, num_walkers=400):\n",
    "    grid = initialize_grid(size)\n",
    "    current_walkers = 0\n",
    "    while current_walkers < num_walkers:\n",
    "        x, y = random.randint(0, size - 1), size - 1\n",
    "        while True:\n",
    "            x, y = move_walker(x, y, size)\n",
    "            if y < 0 or y >= size:\n",
    "                break  # remove walker if it falls off the grid\n",
    "            if is_adjacent(x, y, grid, size):\n",
    "                grid[x, y] = 1 \n",
    "                current_walkers += 1\n",
    "                break\n",
    "    return grid\n",
    "\n",
    "# run simulation\n",
    "size = 100\n",
    "dla_grid = simulate_dla(size, num_walkers=400)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(dla_grid.T, cmap='gray', origin='lower')\n",
    "plt.tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "plt.title(\"Monte Carlo Simulation of DLA (400 walkers)\")\n",
    "plt.savefig(\"figures/B.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7bdda-93a2-40cc-97a9-011a781c8737",
   "metadata": {},
   "source": [
    "- The resulting clusters obtained with the Monte Carlo DLA simulation exhibit a fractal-like structure with some hollow regions. \n",
    "\n",
    "- These hollow spaces arise due to the stochastic nature of the random walkers, as they may not fully explore all possible growth areas. \n",
    "\n",
    "- Unlike the diffusion equation, which results in a smooth density distribution, DLA leads to an irregular and sparse aggregation pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b276af1-8108-434e-acbb-b80708e2f79f",
   "metadata": {},
   "source": [
    "### **C**. (1 point)\n",
    "In this model, the $\\eta$ parameter is no longer easily variable; it is fixed to 1.  However, another parameter can be introduced, namely a sticking probability $p_s$.  The sticking rule can then be stated in the following way:  if the walker enters a cell that is a neighbor of the cluster, it stops there with probability $p_s$.  If it does not stick, the walk continues as normal.  The walker is, however, not allowed to move into a site belonging to the cluster.  Run the simulation for different values of $p_s$, and plot the results.  How does the cluster shape depend on $p_s$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602696e-bed4-42d6-b32c-bcfc2b4428c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def move_walker(x, y):\n",
    "    moves = [(0, 1), (0, -1), (-1, 0), (1, 0)]  # only allow up, down, left, right\n",
    "    dx, dy = moves[np.random.randint(0, 4)]\n",
    "    return x + dx, y + dy\n",
    "\n",
    "@njit\n",
    "def is_adjacent(x, y, grid, size, p_s):\n",
    "    neighbors = [(x-1, y), (x+1, y), (x, y-1), (x, y+1)]\n",
    "    for i, j in neighbors:\n",
    "        if 0 <= i < size and 0 <= j < size and grid[i, j] == 1:\n",
    "            if np.random.rand() < p_s:  # stop with probability p_s\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def simulate_dla(size=100, num_walkers=600, p_s=1.0):\n",
    "    grid = np.zeros((size, size), dtype=int)\n",
    "    grid[size // 2, 0] = 1  # initial cluster at the bottom\n",
    "    current_walkers = 0\n",
    "    while current_walkers < num_walkers:\n",
    "        x, y = np.random.randint(0, size), size - 1  # free a random walker from the top\n",
    "        while True:\n",
    "            try_x, try_y = move_walker(x, y)\n",
    "            try_x = try_x % size\n",
    "            if try_y < 0 or try_y >= size:\n",
    "                break\n",
    "            if grid[try_x, try_y]:  \n",
    "                continue\n",
    "            x, y = try_x, try_y \n",
    "            if is_adjacent(x, y, grid, size, p_s):  \n",
    "                grid[x, y] = 1 \n",
    "                current_walkers += 1\n",
    "                break\n",
    "    return grid\n",
    "\n",
    "size = 100\n",
    "p_values = [0.05, 0.35, 0.65, 0.95]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # 2x2 grid\n",
    "axes = axes.flatten()\n",
    "for i, p_s in enumerate(p_values):\n",
    "    dla_grid = simulate_dla(size, num_walkers=600, p_s=p_s)\n",
    "    axes[i].imshow(dla_grid.T, cmap='gray', origin='lower')\n",
    "    axes[i].set_title(f\"Effective Walkers: 600 ($p_s$ = {p_s})\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/C.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52b6f8-317b-4f81-9141-374ee431c0ef",
   "metadata": {},
   "source": [
    "\n",
    "In question C, a lower $p_s$ allows the walker to keep moving, while a higher $p_s$ results in faster attachment.\n",
    "\n",
    "The experiment tests four cases: $p_s = 0.05, 0.35, 0.65, 0.95$. The results show that lower $p_s$ produces sparser and more elongated aggregates, whereas higher $p_s$ leads to denser and more branched structures.\n",
    "\n",
    "This behavior resembles real-world particle deposition and growth processes. For example, low $p_s$ simulates weak adhesion environments (such as diffusion-limited deposition), while high $p_s$ is more similar to ice crystal growth, electrochemical deposition, or other high-adhesion systems.\n",
    "\n",
    "In conclusion, lower $p_s$ results in a more sparse DLA structure, while higher $p_s$ makes it denser, aligning with the physical properties of the DLA model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52446b-38ea-4600-b95c-863fcda0606f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c07fd-376b-4c3b-85c8-9476f4512f45",
   "metadata": {},
   "source": [
    "## 2.3 The Gray-Scott model - A reaction-diffusion system\n",
    "\n",
    "The Gray-Scott model (J. E. Pearson, *Science*, Vol 261, 5118, 189-192 (1993))  \n",
    "describes a system of chemical reactions, involving the two chemicals $U$ and $V$.  \n",
    "Both chemicals diffuse in the system and also react with each other.  The reaction rate at any point in space is determined by the *local* concentrations of $U$ and $V$.  \n",
    "The reactions are:\n",
    "\n",
    "$$\n",
    "U + 2V \\rightarrow 3V \\tag{15}\n",
    "$$\n",
    "\n",
    "$$\n",
    "V \\rightarrow P \\tag{16}\n",
    "$$\n",
    "\n",
    "$U$ is continuously fed into the system. It then reacts with $V$ to produce more $V$.  $V$ spontaneously decays into $P$, a reaction product that does not interact with $U$ and $V$.  The first reaction is said to be autocatalytic since the reaction product $V$ enhances the production of itself.\n",
    "\n",
    "If we let $u$ and $v$ denote the concentrations of $U$ and $V$,  \n",
    "the following equations can be formulated:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} = D_u \\nabla^2 u - uv^2 + f(1 - u), \\tag{17}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial v}{\\partial t} = D_v \\nabla^2 v + uv^2 - (f + k)v. \\tag{18}\n",
    "$$\n",
    "\n",
    "Here, $f$ controls the rate at which $U$ is supplied,  \n",
    "and $f + k$ controls the rate at which $V$ decays.  For different values of $f$ and $k$, a large variety of behaviors can be observed.  Some result in stable patterns, while others remain time-dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baee08-cba1-4604-8994-49bec2f69f84",
   "metadata": {},
   "source": [
    "### **D**. (3 points)  \n",
    "Implement the Gray-Scott model in two dimensions.  Explain the discretization and how the equations and boundary conditions are implemented in the program (you may choose which boundary conditions to use).  Plot the resulting concentrations of $U$ and/or $V$ for several choices of the parameters. The time-dependent diffusion program from Set 1 can be used as a base.  In this case, there are two variables to keep track of.  For parameters, start with $delta t = 1 $, $delta x = 1$,  $D_u = 0.16 $, $D_v = 0.08$, $f = 0.035$, $k = 0.060$.  For the initial conditions, you can take $u = 0.5$ everywhere in the system,  and $v = 0.25$ in a small square in the center of the system, and 0 outside.  Try adding a small amount of noise too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e69f80-96d4-460e-bc10-b73ebf7fcb01",
   "metadata": {},
   "source": [
    "## Discretization\n",
    "\n",
    "Using the **finite difference method**, the Laplacian operator $  \\nabla^2  $ is approximated as:\n",
    "\n",
    "$$\n",
    "\\nabla^2 u_{i,j} \\approx \\frac{1}{(\\delta x)^2} \\left[ u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j} \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla^2 v_{i,j} \\approx \\frac{1}{(\\delta x)^2} \\left[ v_{i+1,j} + v_{i-1,j} + v_{i,j+1} + v_{i,j-1} - 4v_{i,j} \\right]\n",
    "$$\n",
    "\n",
    "Using the **explicit Euler method**, we approximate the time derivative as:\n",
    "\n",
    "$$\n",
    "u(t + \\delta t, x, y) \\approx u(t, x, y) + \\delta t \\frac{\\partial u}{\\partial t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(t + \\delta t, x, y) \\approx v(t, x, y) + \\delta t \\frac{\\partial v}{\\partial t}\n",
    "$$\n",
    "\n",
    "Substituting the governing equations into these approximations, we obtain:\n",
    "\n",
    "$$\n",
    "u_{i,j}^{n+1} = u_{i,j}^{n} + \\delta t \\left( D_u \\nabla^2 u_{i,j} - u_{i,j} v_{i,j}^2 + f (1 - u_{i,j}) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_{i,j}^{n+1} = v_{i,j}^{n} + \\delta t \\left( D_v \\nabla^2 v_{i,j} + u_{i,j} v_{i,j}^2 - (f + k)v_{i,j} \\right)\n",
    "$$\n",
    "\n",
    "**Final Iterative Update Scheme:**\n",
    "\n",
    "$$\n",
    "u_{i,j}^{n+1} = u_{i,j}^{n} + \\delta t \\left[ D_u \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{(\\delta x)^2} - u_{i,j} v_{i,j}^2 + f(1 - u_{i,j}) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_{i,j}^{n+1} = v_{i,j}^{n} + \\delta t \\left[ D_v \\frac{v_{i+1,j} + v_{i-1,j} + v_{i,j+1} + v_{i,j-1} - 4v_{i,j}}{(\\delta x)^2} + u_{i,j} v_{i,j}^2 - (f + k)v_{i,j} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07377cf2-aa41-4bf6-b3bf-4c32ba9bc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for figures\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")\n",
    "\n",
    "# Parameters\n",
    "N = 100  \n",
    "delta_t = 1.0  \n",
    "delta_x = 1.0  \n",
    "tolerance = 1e-5  # Convergence threshold\n",
    "\n",
    "# Laplacian function with Dirichlet boundary conditions\n",
    "def laplacian_dirichlet(Z, fixed_value=0):\n",
    "    \"\"\"Compute Laplacian with Dirichlet (fixed value) boundary conditions\"\"\"\n",
    "    result = np.zeros_like(Z)\n",
    "    result[1:-1, 1:-1] = (\n",
    "        Z[:-2, 1:-1] + Z[2:, 1:-1] + Z[1:-1, :-2] + Z[1:-1, 2:] - 4 * Z[1:-1, 1:-1]\n",
    "    ) / (delta_x ** 2)\n",
    "    result[0, :] = fixed_value\n",
    "    result[-1, :] = fixed_value\n",
    "    result[:, 0] = fixed_value\n",
    "    result[:, -1] = fixed_value\n",
    "    return result\n",
    "\n",
    "# Gray-Scott model function with automatic convergence check\n",
    "def gray_scott(Du, Dv, f, k, noise, max_iter=50000):\n",
    "    \"\"\"Simulate the Gray-Scott model with Dirichlet boundary conditions and automatic termination\"\"\"\n",
    "    U = np.ones((N, N)) * 0.5 + np.abs(noise * np.random.randn(N, N))  \n",
    "    V = np.zeros((N, N))\n",
    "\n",
    "    # Initial perturbation in the center\n",
    "    r = 10\n",
    "    center = N // 2\n",
    "    U[center-r:center+r, center-r:center+r] = 0.5\n",
    "    V[center-r:center+r, center-r:center+r] = 0.25\n",
    "\n",
    "    for iter_count in range(max_iter):\n",
    "        Lu = laplacian_dirichlet(U, fixed_value=0.5)  \n",
    "        Lv = laplacian_dirichlet(V, fixed_value=0)    \n",
    "\n",
    "        # Compute update step\n",
    "        delta_u = (Du * Lu - U * V**2 + f * (1 - U)) * delta_t\n",
    "        delta_v = (Dv * Lv + U * V**2 - (f + k) * V) * delta_t\n",
    "\n",
    "        # Check convergence\n",
    "        if np.max(np.abs(delta_u[1:-1, 1:-1])) < tolerance and np.max(np.abs(delta_v[1:-1, 1:-1])) < tolerance:\n",
    "            print(f\"Simulation converged at step {iter_count}\")\n",
    "            break\n",
    "\n",
    "        U += delta_u\n",
    "        V += delta_v\n",
    "\n",
    "        # Enforce Dirichlet boundary conditions\n",
    "        U[0, :], U[-1, :], U[:, 0], U[:, -1] = 0.5, 0.5, 0.5, 0.5\n",
    "        V[0, :], V[-1, :], V[:, 0], V[:, -1] = 0, 0, 0, 0\n",
    "\n",
    "    return U, V  \n",
    "\n",
    "# Plot result\n",
    "def plot_result(U, V, params, experiment_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Set titles\n",
    "    title_text = f\"Du={params['Du']}, Dv={params['Dv']}, f={params['f']}, k={params['k']}, noise={params['noise']}\"\n",
    "\n",
    "    # Plot U\n",
    "    im1 = axes[0].imshow(U, cmap=\"inferno\", interpolation=\"bilinear\")\n",
    "    axes[0].set_title(\"U Concentration\", fontsize=12)\n",
    "    fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    # Plot V\n",
    "    im2 = axes[1].imshow(V, cmap=\"magma\", interpolation=\"bilinear\")\n",
    "    axes[1].set_title(\"V Concentration\", fontsize=12)\n",
    "    fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    # Use suptitle for the main parameter title\n",
    "    fig.suptitle(title_text, fontsize=14)\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # Define filename format\n",
    "    filename = f\"figures/{experiment_name}_Du{params['Du']}_Dv{params['Dv']}_f{params['f']}_k{params['k']}_noise{params['noise']}.png\"\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")  # Save figure\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a83540-4c6b-4632-b32d-cffaea5b769b",
   "metadata": {},
   "source": [
    "### Effect of $D_u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f268bc3-f783-4adb-bed4-03b5ae574d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Effect_of_Du\"\n",
    "du_values = [0.14, 0.16, 0.18]\n",
    "\n",
    "for du in du_values:\n",
    "    params = {\"Du\": du, \"Dv\": 0.08, \"f\": 0.035, \"k\": 0.06, \"noise\": 0}\n",
    "    U, V = gray_scott(**params)\n",
    "    plot_result(U, V, params, experiment_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc9c0f-7962-4f3d-b7eb-15171d84584d",
   "metadata": {},
   "source": [
    "### Effect of $D_v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c68dfa-2310-4b70-af5c-618600d3ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Effect_of_Dv\"\n",
    "dv_values = [0.06, 0.08, 0.10]\n",
    "\n",
    "for dv in dv_values:\n",
    "    params = {\"Du\": 0.16, \"Dv\": dv, \"f\": 0.035, \"k\": 0.06, \"noise\": 0}\n",
    "    U, V = gray_scott(**params)\n",
    "    plot_result(U, V, params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54400e-5fd0-49c0-a829-e7bebe5d0df9",
   "metadata": {},
   "source": [
    "### Effect of $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d010b-1bcc-4aec-892e-780084867c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Effect_of_f\"\n",
    "f_values = [0.025, 0.035, 0.045]\n",
    "\n",
    "for f in f_values:\n",
    "    params = {\"Du\": 0.16, \"Dv\": 0.08, \"f\": f, \"k\": 0.06, \"noise\": 0}\n",
    "    U, V = gray_scott(**params)\n",
    "    plot_result(U, V, params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cac9b-a47a-4425-9ce7-4e50f56adc89",
   "metadata": {},
   "source": [
    "### Effect of $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3287a15-db08-4817-940a-f40b945c12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Effect_of_k\"\n",
    "k_values = [0.05, 0.06, 0.07]\n",
    "\n",
    "for k in k_values:\n",
    "    params = {\"Du\": 0.16, \"Dv\": 0.08, \"f\": 0.035, \"k\": k, \"noise\": 0}\n",
    "    U, V = gray_scott(**params)\n",
    "    plot_result(U, V, params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0e8c2-65e2-423c-9fd7-fc693c6bb1cd",
   "metadata": {},
   "source": [
    "### Effect of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f796aa-7b02-4d49-b26b-d181844880a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Effect_of_Noise\"\n",
    "noise_values = [0.001, 0.01]\n",
    "\n",
    "for noise in noise_values:\n",
    "    params = {\"Du\": 0.16, \"Dv\": 0.08, \"f\": 0.035, \"k\": 0.06, \"noise\": noise}\n",
    "    U, V = gray_scott(**params)\n",
    "    plot_result(U, V, params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df756c5-a382-46d7-b8f4-8053306c6a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
